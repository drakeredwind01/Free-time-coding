conda install -c anaconda beautifulsoup4
jupyter notebook --notebook-dir=D:/
jupyter notebook --notebook-dir="D:/documents/GitHub/Free time coding"





from bs4 import BeautifulSoup
import requests
import bs4 as bs
import urllib.request
source = urllib.request.urlopen('https://pythonprogramming.net/parsememcparseface/').read()
url = 'https://terraria.fandom.com/wiki/Category:Item_images'
requests.get(url)

soup = bs.BeautifulSoup(source,'lxml')


# title of the page
print(soup.title)

# get attributes:
print(soup.title.name)

# get values:
print(soup.title.string)

# beginning navigation:
print(soup.title.parent.name)

# getting specific values:
print(soup.p)

for paragraph in soup.find_all('p'):
    print(paragraph.string)
    print(str(paragraph.text))

# get all links
for url in soup.find_all('a'):
    print(url.get('href'))

# print all of everything
print(soup.find_all())

